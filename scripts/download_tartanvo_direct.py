#!/usr/bin/env python3
"""
Direct download of TartanVO dataset using wget/curl.
Alternative approach when TartanAir API fails.
"""

import os
import subprocess
from pathlib import Path
import tarfile
import numpy as np
from tqdm import tqdm

def download_tartanvo_samples():
    """Download TartanVO sample data directly from Azure blob storage."""
    
    base_dir = Path('/mnt/ssd/Conv2d_Datasets/semi_synthetic/tartanvo')
    base_dir.mkdir(parents=True, exist_ok=True)
    
    print("=== Direct TartanVO Download ===")
    print(f"Target directory: {base_dir}")
    print()
    
    # Direct download URLs for sample environments
    # These are smaller samples good for testing
    samples = {
        'ME000': 'https://tartanair.blob.core.windows.net/tartanvo1914/ME000.tar.gz',
        'ME001': 'https://tartanair.blob.core.windows.net/tartanvo1914/ME001.tar.gz',
        'MH000': 'https://tartanair.blob.core.windows.net/tartanvo1914/MH000.tar.gz',
        'MH001': 'https://tartanair.blob.core.windows.net/tartanvo1914/MH001.tar.gz',
    }
    
    downloaded = []
    
    for name, url in samples.items():
        output_file = base_dir / f"{name}.tar.gz"
        
        if output_file.exists():
            print(f"‚úì {name}.tar.gz already exists")
            downloaded.append(output_file)
            continue
            
        print(f"Downloading {name}...")
        
        # Use wget with continue support
        cmd = [
            'wget', 
            '--continue',
            '--progress=bar',
            '--show-progress',
            '-O', str(output_file),
            url
        ]
        
        try:
            subprocess.run(cmd, check=True)
            print(f"‚úÖ Downloaded {name}.tar.gz")
            downloaded.append(output_file)
        except subprocess.CalledProcessError as e:
            print(f"‚ùå Failed to download {name}: {e}")
            # Try curl as fallback
            cmd_curl = [
                'curl', '-L', '-C', '-',
                '-o', str(output_file),
                url
            ]
            try:
                subprocess.run(cmd_curl, check=True)
                print(f"‚úÖ Downloaded {name}.tar.gz with curl")
                downloaded.append(output_file)
            except:
                print(f"‚ùå Both wget and curl failed for {name}")
    
    print(f"\nDownloaded {len(downloaded)} files")
    
    # Extract files
    for tar_file in downloaded:
        extract_dir = base_dir / tar_file.stem
        
        if extract_dir.exists():
            print(f"‚úì {tar_file.stem} already extracted")
            continue
            
        print(f"Extracting {tar_file.name}...")
        
        try:
            with tarfile.open(tar_file, 'r:gz') as tar:
                tar.extractall(base_dir)
            print(f"‚úÖ Extracted to {extract_dir}")
        except Exception as e:
            print(f"‚ùå Failed to extract {tar_file.name}: {e}")
    
    return base_dir

def process_tartanvo_imu(base_dir: Path):
    """Process extracted TartanVO IMU data."""
    
    print("\n=== Processing TartanVO IMU Data ===")
    
    all_data = []
    all_labels = []
    
    # Find all IMU files in extracted directories
    for env_dir in base_dir.glob('M*'):
        if not env_dir.is_dir():
            continue
            
        print(f"\nProcessing {env_dir.name}...")
        
        # Look for IMU files (typically imu.txt or imu_l.txt, imu_r.txt)
        imu_files = list(env_dir.rglob('imu*.txt'))
        
        if not imu_files:
            print(f"  No IMU files found in {env_dir.name}")
            continue
        
        for imu_file in imu_files:
            print(f"  Reading {imu_file.name}")
            
            try:
                # Read IMU data
                # Format: timestamp ax ay az gx gy gz
                data = np.loadtxt(imu_file)
                
                if data.shape[1] < 7:
                    print(f"    Unexpected format: {data.shape}")
                    continue
                
                timestamps = data[:, 0]
                acc_data = data[:, 1:4]  # ax, ay, az
                gyro_data = data[:, 4:7]  # gx, gy, gz
                
                print(f"    Found {len(timestamps)} samples")
                print(f"    Time range: {timestamps[0]:.2f} - {timestamps[-1]:.2f} seconds")
                
                # Window the data (100 samples per window)
                window_size = 100
                stride = 50
                
                for start_idx in range(0, len(data) - window_size, stride):
                    window_acc = acc_data[start_idx:start_idx + window_size]
                    window_gyro = gyro_data[start_idx:start_idx + window_size]
                    
                    # Create 9-channel format (acc, gyro, mag_placeholder)
                    mag_placeholder = np.zeros((window_size, 3))
                    window_9ch = np.concatenate([window_acc, window_gyro, mag_placeholder], axis=1)
                    
                    # Reshape to (9, 2, 100) for Conv2d
                    reshaped = np.zeros((9, 2, window_size))
                    reshaped[:, 0, :] = window_9ch.T
                    # Second spatial dim gets slightly transformed version
                    reshaped[:, 1, :] = window_9ch.T * 0.9
                    
                    all_data.append(reshaped)
                    
                    # Assign pseudo-label based on motion intensity
                    acc_mag = np.linalg.norm(window_acc, axis=1).mean()
                    gyro_mag = np.linalg.norm(window_gyro, axis=1).mean()
                    
                    if acc_mag < 1.0:
                        label = 0  # stationary/stand
                    elif acc_mag < 3.0:
                        label = 1  # walk
                    elif acc_mag < 6.0:
                        label = 2  # trot
                    else:
                        label = 3  # gallop/run
                    
                    all_labels.append(label)
                    
            except Exception as e:
                print(f"    Error processing {imu_file}: {e}")
                continue
    
    if all_data:
        # Convert to numpy arrays
        data_array = np.array(all_data, dtype=np.float32)
        labels_array = np.array(all_labels, dtype=np.int64)
        
        print(f"\n=== Processing Complete ===")
        print(f"Total windows: {len(data_array)}")
        print(f"Data shape: {data_array.shape}")
        print(f"Label distribution:")
        label_names = ['stand', 'walk', 'trot', 'gallop']
        for i, count in enumerate(np.bincount(labels_array)):
            if i < len(label_names):
                print(f"  {label_names[i]}: {count} ({100*count/len(labels_array):.1f}%)")
        
        # Save processed data
        output_dir = base_dir / 'processed'
        output_dir.mkdir(exist_ok=True)
        
        np.savez_compressed(
            output_dir / 'tartanvo_processed.npz',
            data=data_array,
            labels=labels_array,
            label_names=label_names
        )
        
        print(f"\n‚úÖ Saved to {output_dir / 'tartanvo_processed.npz'}")
        
        return data_array, labels_array
    else:
        print("\n‚ùå No data was processed")
        return None, None

def main():
    """Main download and processing pipeline."""
    
    print("TartanVO Direct Download Script")
    print("=" * 50)
    
    # Download samples
    base_dir = download_tartanvo_samples()
    
    # Process IMU data
    data, labels = process_tartanvo_imu(base_dir)
    
    if data is not None:
        print("\nüéâ TartanVO data ready for testing!")
        print("\nNext steps:")
        print("1. Test with Conv2d-FSQ model")
        print("2. Expected accuracy: 75-80% (semi-synthetic)")
        print("3. Compare with PAMAP2 results (65-70% expected)")
    else:
        print("\n‚ö†Ô∏è No data processed. Manual download may be needed.")
        print("\nManual instructions:")
        print("1. Visit https://tartanair.org")
        print("2. Download sample trajectories")
        print("3. Extract to /mnt/ssd/Conv2d_Datasets/semi_synthetic/tartanvo/")

if __name__ == '__main__':
    main()